{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:09.714016Z",
     "start_time": "2019-08-08T19:58:08.241385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqhe-V-vsBfg"
   },
   "source": [
    "# Exercise 1: Cracking the code\n",
    "\n",
    "In this exercise, we will practice our string manipulation skills and intuition about language by working with jumbled text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQ9iUzEztg43"
   },
   "source": [
    "## Part 1: ROT13\n",
    "\n",
    "One of the most simple ways to obfuscate text is the substitution cipher called *ROT13* (*rotate by 13*). In ROT13, each English letter is substituted by the letter 13 places away from it in the English alphabet, as illustrated below:\n",
    "\n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/3/33/ROT13_table_with_example.svg)\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. Write a Python function *rot13* to return the ROT13-encoding of lowercase English letters in the given input text. You may keep uppercase letters unchanged. What is the ROT13 encoding of the string \"Hello world!\" ?\n",
    "2. What is output when you apply the function rot13 twice to the above string? Why?\n",
    "3. Write a function *decode_if_rot13* that decodes text that was jumbled with rot13, and returns plaintext unchanged. For example, it should return the following:\n",
    "\n",
    "  * decode_if_rot13(\"uryyb\") => \"hello\"\n",
    "  * decode_if_rot13(\"hello\") => \"hello\"\n",
    "  * decode_if_rot13(\"guvf vf n grfg\") => \"this is a test\"\n",
    "  * decode_if_rot13(\"vg vf abjurer gb or frra\") => \"it is nowhere to be seen\"\n",
    "  * decode_if_rot13(\"this is a pyrex vessel\") => \"this is a pyrex vessel\"\n",
    "\n",
    "\n",
    "* Hints: Use NLTK's *word_tokenize* function to split the string into word tokens. You may also find NLTK's FreqDist and the Brown corpus data to be useful (*nltk.corpus.brown*).\n",
    "\n",
    "**Bonus:**  Try 1-3 for another language you know. Does ROT13 make sense in this language? How would you modify *decode_if_rot13*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:09.724105Z",
     "start_time": "2019-08-08T19:58:09.716717Z"
    }
   },
   "outputs": [],
   "source": [
    "M_ORD = ord(\"m\")\n",
    "A_ORD = ord(\"a\")\n",
    "N_AWAY = 13\n",
    "\n",
    "def rot13(input_text):\n",
    "    my_rot13 = \"\"\n",
    "    for my_letter in input_text:\n",
    "        letter_ord = ord(my_letter)\n",
    "        if letter_ord <= M_ORD:\n",
    "            if letter_ord >= A_ORD:\n",
    "                my_rot13 += chr(letter_ord + N_AWAY)\n",
    "            else:\n",
    "                my_rot13 += my_letter\n",
    "        else:\n",
    "            my_rot13 += chr(letter_ord - N_AWAY)\n",
    "    return my_rot13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:09.743874Z",
     "start_time": "2019-08-08T19:58:09.728659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hryyb jbeyq!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot13(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:09.770597Z",
     "start_time": "2019-08-08T19:58:09.758317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot13(rot13(\"Hello world!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns the initial string because the rotation is symmetric. the aphabet has 26 letters and 13 is half of that. So we will always find the same word if we apply it twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:16.376792Z",
     "start_time": "2019-08-08T19:58:09.774281Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:21.423397Z",
     "start_time": "2019-08-08T19:58:16.379362Z"
    }
   },
   "outputs": [],
   "source": [
    "BROWN_WORDS = set(brown.words())\n",
    "def decode_if_rot13(input_text):\n",
    "    my_words = set(nltk.word_tokenize(input_text))\n",
    "    for my_word in my_words:\n",
    "        if my_word not in BROWN_WORDS:\n",
    "            return rot13(input_text)\n",
    "        else:\n",
    "            return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:21.455070Z",
     "start_time": "2019-08-08T19:58:21.447976Z"
    }
   },
   "outputs": [],
   "source": [
    "assert decode_if_rot13(\"uryyb\") == \"hello\"\n",
    "assert decode_if_rot13(\"hello\") == \"hello\"\n",
    "assert decode_if_rot13(\"guvf vf n grfg\") == \"this is a test\"\n",
    "assert decode_if_rot13(\"vg vf abjurer gb or frra\") == \"it is nowhere to be seen\"\n",
    "assert decode_if_rot13(\"this is a pyrex vessel\") == \"this is a pyrex vessel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bghFdAH7tqjV"
   },
   "source": [
    "## Part 2: Substitution ciphers\n",
    "\n",
    "More generally, a substitution cipher is a method of encrypting text where each letter is replaced with some other letter of the alphabet. For example, the string \"hello world\" could map to \"qrmmx fxzmg\" under the substitution cipher that maps \"h\" to \"q\", \"e\" to \"r\", \"l\" to \"m\", etc.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "4. Write a function *random_substitution(text)* that encodes text with a random substitution cipher. (You may encode only lowercase letters, and keep uppercase letters and punctuation unchanged.)\n",
    "5. The variable *code* below contains English text that was encoded with some substitution cipher. Recover the original text. Hint: It is recommended to use the Brown corpus in NLTK and NLTK *FreqDist* (or Python's *collections.Counter*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:21.533465Z",
     "start_time": "2019-08-08T19:58:21.500540Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-6l3q_8OuJqF"
   },
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "czwep userj sj c dsrfy wckf leczonsjf oefchfr up hnf lszzsjn oykiczp eydsy fzhfehcszkfzh.\n",
    "hnf jfesfj lyoxjfj yz kxbhs-oybyefr userj anson hep hy jcdf hnfse fwwj leyk weffz-oybyefr iswj, hnfse fzfksfj.\n",
    "szjisefr up oexjn hnf ocjhbf, hnf wckf ncj uffz iecsjfr lye shj jxoofjjlxb oykuszchsyz yl lxz wckfibcp, oyksocb jhpbf, czr bya iesof.\n",
    "shj iyixbceshp bfr hy kczp jisz-yllj, dfejsyzj yl czwep userj oefchfr lye ioj czr dsrfy wckf oyzjybfj, c kceqfh lye kfeonczrsjf lfchxeszw shj oncecohfej, c hfbfdsjfr czskchfr jfesfj, czr c lfchxef lsbk.\n",
    "hnf czwep userj oncecohfej ncdf uffz eflfefzofr sz hfbfdsjsyz ieyweckj hneyxwnyxh hnf ayebr.\n",
    "hnf sjecfbs oykfrp jnya fefhm zfnfrfefh (sz fzwbsjn: c ayzrfelxb oyxzhep), yzf yl hnf zchsyz'j kyjh iyixbce hd ieyweckj, jchsesmfr efofzh lcsbfr sjecfbs-icbfjhszscz ifcof chhfkihj up lfchxeszw hnf czwep userj sz ifcof zfwyhschsyzj ashn hnf iswj.\n",
    "obsij yl hnf jfwkfzh afzh dsecb, wfhhszw dsfafej leyk cbb ceyxzr hnf ayebr.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:21.562315Z",
     "start_time": "2019-08-08T19:58:21.537036Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_substitution(input_text):\n",
    "    letter_list_nums = np.arange(ord(\"a\"),ord(\"z\") + 1)\n",
    "    letter_list = [chr(num) for num in letter_list_nums]\n",
    "    random_array = np.random.choice(letter_list_nums, size=len(letter_list_nums),replace=False)\n",
    "    encode_dict = {}\n",
    "    for my_ind, my_letter in enumerate(letter_list):\n",
    "        encode_dict[my_letter] = random_array[my_ind]\n",
    "    \n",
    "    new_text = \"\"\n",
    "    for my_letter in input_text:\n",
    "        if my_letter.isalpha():\n",
    "            new_text += chr(encode_dict[my_letter])\n",
    "        else: \n",
    "            new_text += my_letter\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:21.587147Z",
     "start_time": "2019-08-08T19:58:21.576132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nujhel zxekw xw u gxkoa huro teujsnxwo seoupok zl pno txjjxwn sarmujl eagxa ojpoepuxjrojp.\\npno woexow tascwow aj rcypx-sayaeok zxekw dnxsn pel pa wugo pnoxe ohhw tear heooj-sayaeok mxhw, pnoxe ojorxow.\\nxjwmxeok zl secwn pno suwpyo, pno huro nuw zooj meuxwok tae xpw wcssowwtcy sarzxjupxaj at tcj huromyul, sarxsuy wplyo, ujk yad mexso.\\nxpw mamcyuexpl yok pa rujl wmxj-attw, goewxajw at ujhel zxekw seoupok tae msw ujk gxkoa huro sajwayow, u rueqop tae roesnujkxwo toupcexjh xpw snueuspoew, u poyogxwok ujxrupok woexow, ujk u toupceo txyr.\\npno ujhel zxekw snueuspoew nugo zooj eotoeojsok xj poyogxwxaj meaheurw pneachnacp pno daeyk.\\npno xweuoyx sarokl wnad oeopv jonokoeop (xj ojhyxwn: u dajkoetcy sacjpel), ajo at pno jupxaj'w rawp mamcyue pg meaheurw, wupxexvok eosojp tuxyok xweuoyx-muyowpxjxuj mouso uppormpw zl toupcexjh pno ujhel zxekw xj mouso johapxupxajw dxpn pno mxhw.\\nsyxmw at pno wohrojp dojp gxeuy, hoppxjh gxodoew tear uyy ueacjk pno daeyk.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_substitution(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T11:00:00.391533Z",
     "start_time": "2019-07-29T10:59:53.105223Z"
    }
   },
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:26.974804Z",
     "start_time": "2019-08-08T19:58:21.595377Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "frequencies = FreqDist(i.lower() for i in brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:26.991224Z",
     "start_time": "2019-08-08T19:58:26.976750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in Brown Corpus: ['the', ',', '.', 'of', 'and', 'to', 'a', 'in', 'that', 'is']\n"
     ]
    }
   ],
   "source": [
    "print('Most common words in Brown Corpus:', [word for word, f in frequencies.most_common(n=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:27.004643Z",
     "start_time": "2019-08-08T19:58:26.993812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in the code: ['hnf', 'userj', 'c', 'czwep', 'yl', 'wckf', 'up', 'lye', 'shj', 'czr']\n"
     ]
    }
   ],
   "source": [
    "print('Most common words in the code:', [word for word, f in FreqDist(code.split()).most_common(n=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already deduce some identities from the above output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:27.032964Z",
     "start_time": "2019-08-08T19:58:27.007817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partially decoded: \n",
      "ANwep useDj sj A dsDEy wAkE leANoHsjE oeEATED up THE lsNNsjH oykiANp eydsy ENTEeTAsNkENT.\n",
      "THE jEesEj lyoxjEj yN kxbTs-oybyeED useDj aHsoH Tep Ty jAdE THEse Ewwj leyk weEEN-oybyeED iswj, THEse ENEksEj.\n",
      "sNjiseED up oexjH THE oAjTbE, THE wAkE HAj uEEN ieAsjED lye sTj jxooEjjlxb oykusNATsyN yl lxN wAkEibAp, oyksoAb jTpbE, AND bya iesoE.\n",
      "sTj iyixbAesTp bED Ty kANp jisN-yllj, dEejsyNj yl ANwep useDj oeEATED lye ioj AND dsDEy wAkE oyNjybEj, A kAeqET lye kEeoHANDsjE lEATxesNw sTj oHAeAoTEej, A TEbEdsjED ANskATED jEesEj, AND A lEATxeE lsbk.\n",
      "THE ANwep useDj oHAeAoTEej HAdE uEEN eElEeENoED sN TEbEdsjsyN ieyweAkj THeyxwHyxT THE ayebD.\n",
      "THE sjeAEbs oykEDp jHya EeETm NEHEDEeET (sN ENwbsjH: A ayNDEelxb oyxNTep), yNE yl THE NATsyN'j kyjT iyixbAe Td ieyweAkj, jATsesmED eEoENT lAsbED sjeAEbs-iAbEjTsNsAN iEAoE ATTEkiTj up lEATxesNw THE ANwep useDj sN iEAoE NEwyTsATsyNj asTH THE iswj.\n",
      "obsij yl THE jEwkENT aENT dseAb, wETTsNw dsEaEej leyk Abb AeyxND THE ayebD.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Partially decoded:', ''.join({'c':'A', 'h':'T', 'n':'H', 'f':'E', 'z':'N', 'r':'D'}.get(char,char) for char in code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can deduce the remaining identities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:58:27.056305Z",
     "start_time": "2019-08-08T19:58:27.042627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully decoded: \n",
      "angry birds is a video game franchise created by the finnish company rovio entertainment.\n",
      "the series focuses on multi-colored birds which try to save their eggs from green-colored pigs, their enemies.\n",
      "inspired by crush the castle, the game has been praised for its successful combination of fun gameplay, comical style, and low price.\n",
      "its popularity led to many spin-offs, versions of angry birds created for pcs and video game consoles, a market for merchandise featuring its characters, a televised animated series, and a feature film.\n",
      "the angry birds characters have been referenced in television programs throughout the world.\n",
      "the israeli comedy show eretz nehederet (in english: a wonderful country), one of the nation's most popular tv programs, satirized recent failed israeli-palestinian peace attempts by featuring the angry birds in peace negotiations with the pigs.\n",
      "clips of the segment went viral, getting viewers from all around the world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Fully decoded:', ''.join({'a':'w', 'b':'l', 'c':'a', 'd':'v', 'e':'r', 'f':'e', 'g':'q', 'h':'t', 'i':'p',\n",
    "                                 'j':'s', 'k':'m', 'l':'f', 'm':'z', 'n':'h', 'o':'c', 'p':'y', 'q':'k','r':'d', \n",
    "                                's':'i', 't':'j', 'u':'b', 'v':'x', 'w':'g', 'x':'u', 'y':'o', 'z':'n'\n",
    "                                }.get(char,char) for char in code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEOUv4aZK6DE"
   },
   "source": [
    "**Bonus:** How would you write a function *decipher* to decipher arbitrary text in some substitution cipher? (There's no one right answer.)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP Core 1 Exercise 1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
