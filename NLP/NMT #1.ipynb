{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJv1d7p9QfuH"
   },
   "source": [
    "# NMT Workshop Exercise 1: Keras Sequential vs. Functional APIs\n",
    "\n",
    "In this exercise, we will practice using the two APIs that Keras provides for building deep learning models: the Keras Sequential and Functional APIs.\n",
    "\n",
    "If you need to reference the syntax of either model, see the Keras documentation pages on the [Sequential](https://keras.io/getting-started/sequential-model-guide/) and [Functional](https://keras.io/getting-started/functional-api-guide/) APIs.\n",
    "\n",
    "## Part 1: Sequential Voting\n",
    "\n",
    "For our toy problem, we will use the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T06:34:25.559741Z",
     "start_time": "2019-08-08T06:34:25.541220Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rYFGAmdlDetE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.randint(0, 2, size = (1000, 9))\n",
    "Y = np.where(np.mean(X, axis = 1) > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8464JhZ3_8iO"
   },
   "source": [
    "**Questions:**\n",
    "1. What does it mean that the elements of Y represent a \"majority vote\" on X?\n",
    "2. We want to learn how to predict elements of Y from rows of X. Build a Keras Sequential model *model* with one Dense layer (with activation = 'sigmoid') that can be fit on X and Y. Check that the input and output shapes of the model (*model.input_shape* and *model.output_shape*) match the shapes of X and Y.\n",
    "3. Compile the model with 'mean_squared_error' loss, 'rmsprop' optimizer, and *metrics = ['accuracy']*, and fit it to X and Y with *validation_split = 0.2*. You may choose any values for *epochs* and *batch_size* that result in the model learning well.\n",
    "4. Once the model has been fit, examine the values of *model.get_weights()*. How do you interpret these values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Y is a vector where 1 occurs if for any line in X, the average of all the values in the vestor is above 0.5, and 0 otherwise. So 1 occurs when there are more 1s than 0s and 0 occurs when there are more 0s than 1s. Therefore it is a majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T08:05:51.182343Z",
     "start_time": "2019-08-08T08:05:51.162389Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T16:27:24.223950Z",
     "start_time": "2019-08-08T16:27:22.186829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_size = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=x_size))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T16:28:54.778799Z",
     "start_time": "2019-08-08T16:27:24.538573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3388 - acc: 0.4350 - val_loss: 0.3148 - val_acc: 0.3750\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2937 - acc: 0.4300 - val_loss: 0.2695 - val_acc: 0.4450\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.2657 - acc: 0.5113 - val_loss: 0.2469 - val_acc: 0.5800\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2536 - acc: 0.5663 - val_loss: 0.2375 - val_acc: 0.6050\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 398us/step - loss: 0.2464 - acc: 0.5838 - val_loss: 0.2310 - val_acc: 0.6050\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2412 - acc: 0.5763 - val_loss: 0.2265 - val_acc: 0.6100\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2366 - acc: 0.5900 - val_loss: 0.2223 - val_acc: 0.6100\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.2321 - acc: 0.6000 - val_loss: 0.2182 - val_acc: 0.6350\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 701us/step - loss: 0.2275 - acc: 0.6263 - val_loss: 0.2140 - val_acc: 0.6400\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.2231 - acc: 0.6425 - val_loss: 0.2102 - val_acc: 0.6700\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.2187 - acc: 0.6488 - val_loss: 0.2063 - val_acc: 0.6800\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.2146 - acc: 0.6625 - val_loss: 0.2027 - val_acc: 0.6950\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 905us/step - loss: 0.2106 - acc: 0.6850 - val_loss: 0.1991 - val_acc: 0.6950\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2067 - acc: 0.6963 - val_loss: 0.1955 - val_acc: 0.7100\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2029 - acc: 0.7100 - val_loss: 0.1920 - val_acc: 0.7200\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1992 - acc: 0.7163 - val_loss: 0.1888 - val_acc: 0.7300\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1958 - acc: 0.7275 - val_loss: 0.1856 - val_acc: 0.7350\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1923 - acc: 0.7375 - val_loss: 0.1823 - val_acc: 0.7550\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1888 - acc: 0.7588 - val_loss: 0.1791 - val_acc: 0.7600\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.1852 - acc: 0.7625 - val_loss: 0.1758 - val_acc: 0.7750\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1819 - acc: 0.7788 - val_loss: 0.1730 - val_acc: 0.7900\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1787 - acc: 0.7888 - val_loss: 0.1700 - val_acc: 0.8300\n",
      "Epoch 23/100\n",
      " 85/800 [==>...........................] - ETA: 5s - loss: 0.1747 - acc: 0.8353"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yohan/Desktop/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.120115). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 4s 4ms/step - loss: 0.1756 - acc: 0.8200 - val_loss: 0.1669 - val_acc: 0.8350oss: 0.1776 - acc\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 0.1726 - acc: 0.8263 - val_loss: 0.1640 - val_acc: 0.8350\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1697 - acc: 0.8213 - val_loss: 0.1614 - val_acc: 0.8400\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1671 - acc: 0.8238 - val_loss: 0.1591 - val_acc: 0.8650\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1644 - acc: 0.8375 - val_loss: 0.1567 - val_acc: 0.8700\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1620 - acc: 0.8513 - val_loss: 0.1543 - val_acc: 0.8700\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.1595 - acc: 0.8575 - val_loss: 0.1518 - val_acc: 0.8800\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1571 - acc: 0.8500 - val_loss: 0.1496 - val_acc: 0.8800\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1549 - acc: 0.8700 - val_loss: 0.1474 - val_acc: 0.8850\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 786us/step - loss: 0.1526 - acc: 0.8800 - val_loss: 0.1451 - val_acc: 0.8850\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 742us/step - loss: 0.1505 - acc: 0.8875 - val_loss: 0.1430 - val_acc: 0.9000\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 613us/step - loss: 0.1482 - acc: 0.9013 - val_loss: 0.1408 - val_acc: 0.9200\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 558us/step - loss: 0.1461 - acc: 0.8950 - val_loss: 0.1389 - val_acc: 0.9250\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 481us/step - loss: 0.1442 - acc: 0.9050 - val_loss: 0.1369 - val_acc: 0.9250\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 549us/step - loss: 0.1423 - acc: 0.9038 - val_loss: 0.1353 - val_acc: 0.9300\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 541us/step - loss: 0.1404 - acc: 0.9138 - val_loss: 0.1335 - val_acc: 0.9300\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 687us/step - loss: 0.1387 - acc: 0.9213 - val_loss: 0.1317 - val_acc: 0.9300\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 870us/step - loss: 0.1368 - acc: 0.9325 - val_loss: 0.1298 - val_acc: 0.9300\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1350 - acc: 0.9263 - val_loss: 0.1282 - val_acc: 0.9350\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 913us/step - loss: 0.1333 - acc: 0.9388 - val_loss: 0.1265 - val_acc: 0.9350\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 947us/step - loss: 0.1317 - acc: 0.9425 - val_loss: 0.1248 - val_acc: 0.9400\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 627us/step - loss: 0.1300 - acc: 0.9425 - val_loss: 0.1233 - val_acc: 0.9450\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 691us/step - loss: 0.1285 - acc: 0.9525 - val_loss: 0.1218 - val_acc: 0.9500\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 541us/step - loss: 0.1270 - acc: 0.9513 - val_loss: 0.1204 - val_acc: 0.9500\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 513us/step - loss: 0.1255 - acc: 0.9738 - val_loss: 0.1188 - val_acc: 0.9500\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 838us/step - loss: 0.1241 - acc: 0.9675 - val_loss: 0.1175 - val_acc: 0.9500\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 824us/step - loss: 0.1226 - acc: 0.9663 - val_loss: 0.1160 - val_acc: 0.9550\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 497us/step - loss: 0.1213 - acc: 0.9738 - val_loss: 0.1147 - val_acc: 0.9600\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 497us/step - loss: 0.1198 - acc: 0.9738 - val_loss: 0.1135 - val_acc: 0.9750\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 555us/step - loss: 0.1185 - acc: 0.9838 - val_loss: 0.1121 - val_acc: 0.9650\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 718us/step - loss: 0.1172 - acc: 0.9838 - val_loss: 0.1106 - val_acc: 0.9650\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1160 - acc: 0.9838 - val_loss: 0.1094 - val_acc: 0.9850\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 675us/step - loss: 0.1147 - acc: 0.9850 - val_loss: 0.1083 - val_acc: 0.9850\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 631us/step - loss: 0.1136 - acc: 0.9850 - val_loss: 0.1073 - val_acc: 0.9850\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 825us/step - loss: 0.1124 - acc: 0.9900 - val_loss: 0.1062 - val_acc: 0.9900\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 644us/step - loss: 0.1112 - acc: 0.9888 - val_loss: 0.1050 - val_acc: 0.9900\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 663us/step - loss: 0.1101 - acc: 0.9875 - val_loss: 0.1041 - val_acc: 0.9950\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 695us/step - loss: 0.1091 - acc: 0.9938 - val_loss: 0.1029 - val_acc: 0.9850\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 607us/step - loss: 0.1080 - acc: 0.9888 - val_loss: 0.1018 - val_acc: 0.9950\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 603us/step - loss: 0.1069 - acc: 0.9913 - val_loss: 0.1008 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 976us/step - loss: 0.1059 - acc: 0.9975 - val_loss: 0.0997 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 711us/step - loss: 0.1048 - acc: 0.9963 - val_loss: 0.0987 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 777us/step - loss: 0.1039 - acc: 0.9950 - val_loss: 0.0979 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 611us/step - loss: 0.1029 - acc: 0.9975 - val_loss: 0.0969 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 563us/step - loss: 0.1018 - acc: 0.9975 - val_loss: 0.0963 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 709us/step - loss: 0.1009 - acc: 0.9975 - val_loss: 0.0954 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 480us/step - loss: 0.1000 - acc: 0.9975 - val_loss: 0.0944 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 643us/step - loss: 0.0991 - acc: 0.9988 - val_loss: 0.0936 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 512us/step - loss: 0.0983 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 622us/step - loss: 0.0974 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 758us/step - loss: 0.0967 - acc: 0.9988 - val_loss: 0.0912 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 505us/step - loss: 0.0959 - acc: 0.9975 - val_loss: 0.0906 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 544us/step - loss: 0.0951 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 532us/step - loss: 0.0943 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 562us/step - loss: 0.0935 - acc: 1.0000 - val_loss: 0.0883 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 413us/step - loss: 0.0928 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 487us/step - loss: 0.0920 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 592us/step - loss: 0.0913 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 961us/step - loss: 0.0906 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 634us/step - loss: 0.0899 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 488us/step - loss: 0.0891 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 594us/step - loss: 0.0885 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 521us/step - loss: 0.0878 - acc: 1.0000 - val_loss: 0.0827 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 669us/step - loss: 0.0872 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 568us/step - loss: 0.0865 - acc: 1.0000 - val_loss: 0.0815 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 558us/step - loss: 0.0859 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 483us/step - loss: 0.0853 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 537us/step - loss: 0.0847 - acc: 1.0000 - val_loss: 0.0798 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 542us/step - loss: 0.0841 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 492us/step - loss: 0.0835 - acc: 1.0000 - val_loss: 0.0787 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 468us/step - loss: 0.0829 - acc: 1.0000 - val_loss: 0.0782 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 551us/step - loss: 0.0823 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 514us/step - loss: 0.0818 - acc: 1.0000 - val_loss: 0.0769 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 467us/step - loss: 0.0812 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 424us/step - loss: 0.0806 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 411us/step - loss: 0.0800 - acc: 1.0000 - val_loss: 0.0757 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 420us/step - loss: 0.0795 - acc: 1.0000 - val_loss: 0.0749 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 551us/step - loss: 0.0790 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb33e014a8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs = 100, batch_size=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T08:33:05.262775Z",
     "start_time": "2019-08-08T08:33:05.205918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.7097542 ],\n",
       "        [0.6210766 ],\n",
       "        [0.63398135],\n",
       "        [0.6162154 ],\n",
       "        [0.7539241 ],\n",
       "        [0.6845351 ],\n",
       "        [0.51169944],\n",
       "        [0.73884153],\n",
       "        [0.61793715]], dtype=float32), array([-2.7795007], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T08:41:52.589427Z",
     "start_time": "2019-08-08T08:41:52.582705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T08:42:00.160962Z",
     "start_time": "2019-08-08T08:42:00.152829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are similar for each feature since all features have the same distribution and Y is based on an arithmetic function (arithmetic mean) of the features in X where all the features have the same weight in the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFtx0doq-c1B"
   },
   "source": [
    "## Part 2: Making it Functional\n",
    "\n",
    "Now we will practice using Keras's Functional API by rewriting the above model.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "5. Create a model *model2* identical to the above model, but using the Keras Functional API. The model should include an *Input(shape=...)* layer from keras.layers and should use *Model(inputs = ..., outputs = ...)* from keras.models. Fit this model and verify that it produces the same results, and compare the outputs of *model.summary()* and *model2.summary()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T16:17:37.709061Z",
     "start_time": "2019-08-08T16:17:34.718262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(x_size,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(1, activation='sigmoid')(inputs)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model2 = Model(inputs=inputs, outputs=x)\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T16:18:27.135703Z",
     "start_time": "2019-08-08T16:17:37.948141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/70\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.2903 - acc: 0.4563 - val_loss: 0.2760 - val_acc: 0.4450\n",
      "Epoch 2/70\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2710 - acc: 0.5063 - val_loss: 0.2565 - val_acc: 0.5450\n",
      "Epoch 3/70\n",
      "800/800 [==============================] - 1s 774us/step - loss: 0.2598 - acc: 0.5413 - val_loss: 0.2463 - val_acc: 0.5800\n",
      "Epoch 4/70\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2530 - acc: 0.5688 - val_loss: 0.2393 - val_acc: 0.5850\n",
      "Epoch 5/70\n",
      "800/800 [==============================] - 0s 553us/step - loss: 0.2471 - acc: 0.5738 - val_loss: 0.2329 - val_acc: 0.6000\n",
      "Epoch 6/70\n",
      "800/800 [==============================] - 1s 674us/step - loss: 0.2411 - acc: 0.5788 - val_loss: 0.2270 - val_acc: 0.5950\n",
      "Epoch 7/70\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.2352 - acc: 0.596 - 1s 2ms/step - loss: 0.2355 - acc: 0.5963 - val_loss: 0.2218 - val_acc: 0.6100\n",
      "Epoch 8/70\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.2302 - acc: 0.6125 - val_loss: 0.2167 - val_acc: 0.6400\n",
      "Epoch 9/70\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2249 - acc: 0.6275 - val_loss: 0.2116 - val_acc: 0.6700\n",
      "Epoch 10/70\n",
      "800/800 [==============================] - 1s 667us/step - loss: 0.2201 - acc: 0.6425 - val_loss: 0.2071 - val_acc: 0.6900\n",
      "Epoch 11/70\n",
      "800/800 [==============================] - 1s 745us/step - loss: 0.2154 - acc: 0.6600 - val_loss: 0.2027 - val_acc: 0.7150\n",
      "Epoch 12/70\n",
      "800/800 [==============================] - 1s 827us/step - loss: 0.2109 - acc: 0.6763 - val_loss: 0.1986 - val_acc: 0.7450\n",
      "Epoch 13/70\n",
      "800/800 [==============================] - 0s 540us/step - loss: 0.2067 - acc: 0.6950 - val_loss: 0.1946 - val_acc: 0.7450\n",
      "Epoch 14/70\n",
      "800/800 [==============================] - 0s 568us/step - loss: 0.2024 - acc: 0.7038 - val_loss: 0.1908 - val_acc: 0.7600\n",
      "Epoch 15/70\n",
      "800/800 [==============================] - 0s 490us/step - loss: 0.1981 - acc: 0.7213 - val_loss: 0.1869 - val_acc: 0.7700\n",
      "Epoch 16/70\n",
      "800/800 [==============================] - 0s 458us/step - loss: 0.1942 - acc: 0.7325 - val_loss: 0.1834 - val_acc: 0.7850\n",
      "Epoch 17/70\n",
      "800/800 [==============================] - 0s 605us/step - loss: 0.1904 - acc: 0.7550 - val_loss: 0.1796 - val_acc: 0.7900\n",
      "Epoch 18/70\n",
      "800/800 [==============================] - 0s 532us/step - loss: 0.1866 - acc: 0.7425 - val_loss: 0.1762 - val_acc: 0.7950\n",
      "Epoch 19/70\n",
      "800/800 [==============================] - 0s 591us/step - loss: 0.1831 - acc: 0.7675 - val_loss: 0.1731 - val_acc: 0.8150\n",
      "Epoch 20/70\n",
      "800/800 [==============================] - 0s 422us/step - loss: 0.1799 - acc: 0.7863 - val_loss: 0.1702 - val_acc: 0.8200\n",
      "Epoch 21/70\n",
      "800/800 [==============================] - 0s 610us/step - loss: 0.1767 - acc: 0.7925 - val_loss: 0.1673 - val_acc: 0.8250: 0s - loss: 0.1761 - acc: 0.79\n",
      "Epoch 22/70\n",
      "800/800 [==============================] - 0s 461us/step - loss: 0.1735 - acc: 0.8025 - val_loss: 0.1643 - val_acc: 0.8300\n",
      "Epoch 23/70\n",
      "800/800 [==============================] - 0s 543us/step - loss: 0.1706 - acc: 0.8138 - val_loss: 0.1616 - val_acc: 0.8300\n",
      "Epoch 24/70\n",
      "800/800 [==============================] - 0s 514us/step - loss: 0.1679 - acc: 0.8225 - val_loss: 0.1588 - val_acc: 0.8300\n",
      "Epoch 25/70\n",
      "800/800 [==============================] - 0s 532us/step - loss: 0.1650 - acc: 0.8075 - val_loss: 0.1562 - val_acc: 0.8350\n",
      "Epoch 26/70\n",
      "800/800 [==============================] - 0s 558us/step - loss: 0.1624 - acc: 0.8088 - val_loss: 0.1539 - val_acc: 0.8500\n",
      "Epoch 27/70\n",
      "800/800 [==============================] - 0s 576us/step - loss: 0.1599 - acc: 0.8350 - val_loss: 0.1515 - val_acc: 0.8300\n",
      "Epoch 28/70\n",
      "800/800 [==============================] - 1s 868us/step - loss: 0.1575 - acc: 0.8088 - val_loss: 0.1494 - val_acc: 0.8750\n",
      "Epoch 29/70\n",
      "800/800 [==============================] - 0s 503us/step - loss: 0.1552 - acc: 0.8425 - val_loss: 0.1472 - val_acc: 0.8900\n",
      "Epoch 30/70\n",
      "800/800 [==============================] - 0s 528us/step - loss: 0.1529 - acc: 0.8588 - val_loss: 0.1450 - val_acc: 0.8850\n",
      "Epoch 31/70\n",
      "800/800 [==============================] - 0s 501us/step - loss: 0.1506 - acc: 0.8775 - val_loss: 0.1427 - val_acc: 0.8850\n",
      "Epoch 32/70\n",
      "800/800 [==============================] - 0s 607us/step - loss: 0.1484 - acc: 0.8788 - val_loss: 0.1408 - val_acc: 0.9300\n",
      "Epoch 33/70\n",
      "800/800 [==============================] - 0s 535us/step - loss: 0.1464 - acc: 0.9150 - val_loss: 0.1388 - val_acc: 0.9250\n",
      "Epoch 34/70\n",
      "800/800 [==============================] - 0s 570us/step - loss: 0.1444 - acc: 0.9175 - val_loss: 0.1368 - val_acc: 0.9300\n",
      "Epoch 35/70\n",
      "800/800 [==============================] - 0s 526us/step - loss: 0.1424 - acc: 0.9313 - val_loss: 0.1348 - val_acc: 0.9200\n",
      "Epoch 36/70\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1405 - acc: 0.9200 - val_loss: 0.1332 - val_acc: 0.9350TA: 1s - loss: 0\n",
      "Epoch 37/70\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1386 - acc: 0.9300 - val_loss: 0.1314 - val_acc: 0.9500\n",
      "Epoch 38/70\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.1367 - acc: 0.9588 - val_loss: 0.1294 - val_acc: 0.9350\n",
      "Epoch 39/70\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.1350 - acc: 0.9425 - val_loss: 0.1279 - val_acc: 0.9450\n",
      "Epoch 40/70\n",
      "800/800 [==============================] - 1s 932us/step - loss: 0.1333 - acc: 0.9425 - val_loss: 0.1265 - val_acc: 0.9550\n",
      "Epoch 41/70\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1318 - acc: 0.9550 - val_loss: 0.1249 - val_acc: 0.9550\n",
      "Epoch 42/70\n",
      "800/800 [==============================] - 0s 613us/step - loss: 0.1302 - acc: 0.9613 - val_loss: 0.1233 - val_acc: 0.9500\n",
      "Epoch 43/70\n",
      "800/800 [==============================] - 1s 818us/step - loss: 0.1287 - acc: 0.9550 - val_loss: 0.1219 - val_acc: 0.9600\n",
      "Epoch 44/70\n",
      "800/800 [==============================] - 1s 856us/step - loss: 0.1272 - acc: 0.9663 - val_loss: 0.1204 - val_acc: 0.9600\n",
      "Epoch 45/70\n",
      "800/800 [==============================] - 1s 881us/step - loss: 0.1259 - acc: 0.9625 - val_loss: 0.1191 - val_acc: 0.9600\n",
      "Epoch 46/70\n",
      "800/800 [==============================] - 1s 794us/step - loss: 0.1243 - acc: 0.9713 - val_loss: 0.1176 - val_acc: 0.9650\n",
      "Epoch 47/70\n",
      "800/800 [==============================] - 1s 768us/step - loss: 0.1228 - acc: 0.9763 - val_loss: 0.1162 - val_acc: 0.9650\n",
      "Epoch 48/70\n",
      "800/800 [==============================] - 1s 761us/step - loss: 0.1214 - acc: 0.9838 - val_loss: 0.1147 - val_acc: 0.9650\n",
      "Epoch 49/70\n",
      "800/800 [==============================] - 1s 713us/step - loss: 0.1201 - acc: 0.9825 - val_loss: 0.1135 - val_acc: 0.9650\n",
      "Epoch 50/70\n",
      "800/800 [==============================] - 1s 870us/step - loss: 0.1188 - acc: 0.9825 - val_loss: 0.1122 - val_acc: 0.9850\n",
      "Epoch 51/70\n",
      "800/800 [==============================] - 1s 634us/step - loss: 0.1175 - acc: 0.9863 - val_loss: 0.1109 - val_acc: 0.9850\n",
      "Epoch 52/70\n",
      "800/800 [==============================] - 0s 583us/step - loss: 0.1163 - acc: 0.9838 - val_loss: 0.1098 - val_acc: 0.9850\n",
      "Epoch 53/70\n",
      "800/800 [==============================] - 0s 514us/step - loss: 0.1150 - acc: 0.9875 - val_loss: 0.1086 - val_acc: 0.9850\n",
      "Epoch 54/70\n",
      "800/800 [==============================] - 1s 700us/step - loss: 0.1139 - acc: 0.9875 - val_loss: 0.1074 - val_acc: 0.9850\n",
      "Epoch 55/70\n",
      "800/800 [==============================] - 1s 693us/step - loss: 0.1128 - acc: 0.9863 - val_loss: 0.1065 - val_acc: 0.9850\n",
      "Epoch 56/70\n",
      "800/800 [==============================] - 1s 694us/step - loss: 0.1116 - acc: 0.9913 - val_loss: 0.1054 - val_acc: 0.9950\n",
      "Epoch 57/70\n",
      "800/800 [==============================] - 0s 558us/step - loss: 0.1106 - acc: 0.9913 - val_loss: 0.1044 - val_acc: 1.0000\n",
      "Epoch 58/70\n",
      "800/800 [==============================] - 0s 456us/step - loss: 0.1095 - acc: 0.9938 - val_loss: 0.1032 - val_acc: 1.0000\n",
      "Epoch 59/70\n",
      "800/800 [==============================] - 0s 574us/step - loss: 0.1084 - acc: 0.9925 - val_loss: 0.1024 - val_acc: 1.0000\n",
      "Epoch 60/70\n",
      "800/800 [==============================] - 0s 618us/step - loss: 0.1074 - acc: 0.9938 - val_loss: 0.1014 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/70\n",
      "800/800 [==============================] - 0s 411us/step - loss: 0.1064 - acc: 0.9975 - val_loss: 0.1003 - val_acc: 1.0000\n",
      "Epoch 62/70\n",
      "800/800 [==============================] - 0s 491us/step - loss: 0.1054 - acc: 0.9938 - val_loss: 0.0994 - val_acc: 1.0000\n",
      "Epoch 63/70\n",
      "800/800 [==============================] - 0s 486us/step - loss: 0.1044 - acc: 0.9975 - val_loss: 0.0985 - val_acc: 1.0000\n",
      "Epoch 64/70\n",
      "800/800 [==============================] - 0s 500us/step - loss: 0.1034 - acc: 0.9975 - val_loss: 0.0976 - val_acc: 1.0000\n",
      "Epoch 65/70\n",
      "800/800 [==============================] - 0s 613us/step - loss: 0.1025 - acc: 0.9975 - val_loss: 0.0967 - val_acc: 1.0000\n",
      "Epoch 66/70\n",
      "800/800 [==============================] - 0s 531us/step - loss: 0.1015 - acc: 0.9975 - val_loss: 0.0957 - val_acc: 1.0000\n",
      "Epoch 67/70\n",
      "800/800 [==============================] - 0s 449us/step - loss: 0.1006 - acc: 0.9963 - val_loss: 0.0951 - val_acc: 1.0000\n",
      "Epoch 68/70\n",
      "800/800 [==============================] - 0s 541us/step - loss: 0.0998 - acc: 0.9988 - val_loss: 0.0943 - val_acc: 1.0000\n",
      "Epoch 69/70\n",
      "800/800 [==============================] - 0s 500us/step - loss: 0.0988 - acc: 0.9975 - val_loss: 0.0934 - val_acc: 1.0000\n",
      "Epoch 70/70\n",
      "800/800 [==============================] - 0s 561us/step - loss: 0.0980 - acc: 0.9975 - val_loss: 0.0926 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb35295e10>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, Y, epochs = 70, batch_size=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T08:41:11.394766Z",
     "start_time": "2019-08-08T08:41:11.347722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.69297874],\n",
       "        [0.63488173],\n",
       "        [0.6455374 ],\n",
       "        [0.60682154],\n",
       "        [0.7568716 ],\n",
       "        [0.68070287],\n",
       "        [0.51847893],\n",
       "        [0.73426604],\n",
       "        [0.6264585 ]], dtype=float32), array([-2.7952757], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T08:42:33.609195Z",
     "start_time": "2019-08-08T08:42:33.602145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T08:42:14.887753Z",
     "start_time": "2019-08-08T08:42:14.881625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPHD9bYRQlOx"
   },
   "source": [
    "## Part 3: Identifying identical distributions\n",
    "\n",
    "The previous problem had a nice solution using the Keras Sequential API, but sometimes we will need the Functional API to build more complicated networks. Let's try to learn a slightly more complicated pattern that will be solved more naturally with the Functional API.\n",
    "\n",
    "Let's generate another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T08:44:02.685978Z",
     "start_time": "2019-08-08T08:44:02.562134Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "onpaNUgHmY6F"
   },
   "outputs": [],
   "source": [
    "M1 = np.array([np.random.choice([-10, 10]) for i in range(1000)])\n",
    "M2 = np.array([np.random.choice([-10, 10]) for i in range(1000)])\n",
    "S1 = np.stack([\n",
    "    np.random.normal(m, 1, size = 5)\n",
    "    for m in M1\n",
    "])\n",
    "S2 = np.stack([\n",
    "    np.random.normal(m, 1, size = 5)\n",
    "    for m in M2\n",
    "])\n",
    "labels = np.where(M1 == M2, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gjvYjkiFdhY"
   },
   "source": [
    "Every row of S1 and S2 is a sample of 5 elements from a distribution with mean either -10 or 10, and the labels in *label* represent whether the given samples are drawn from the same distribution (0: different distributions, 1: same distribution).\n",
    "\n",
    "We want to train a model to learn how to predict if the two given samples of 5 data points are drawn from the same distribution, i.e. whether they have the same mean.\n",
    "\n",
    "**Questions:**\n",
    "6. Create a Functional model using the following architecture:\n",
    "  * Two Input layers *inp1* and *inp2* (make sure that each has the right *shape=...* parameter)\n",
    "  * A Dense layer *shared_dense* with output dimension 1 and sigmoid activation function, shared between the input layers. (Define the Dense layer as *shared_dense = Dense(...)* and then set *x1 = shared_dense(inp1)* and *x2 = shared_dense(inp2)*). This means that the same weights will be applied to both inputs.\n",
    "  * Concatenate the outputs of the dense layers together with *merged = concatenate([x1, x2])*\n",
    "  * A Dense layer with output dimension 4 and sigmoid activation function, applied to *merged*\n",
    "  * Another Dense layer with output dimension 1 and sigmoid activation function\n",
    "  * Finally, define the model as *func_model = Model(inputs = ..., outputs = ...)* for the proper inputs and outputs parameters.\n",
    "7. Examine the input and output shapes of *func_model* and verify that they match *S1*, *S2*, and *labels*.\n",
    "8. Compile *func_model* with optimiser *rmsprop*, *binary_crossentropy* loss, and *metrics = ['accuracy']* and fit to *[S1, S2]* and *labels* with *validation_split = 0.2*. Hint: you can use *epochs = 100* and *batch_size = 8* if you are unsure of good values for these hyperparameters. What is the final accuracy that this model achieves?\n",
    "\n",
    "**Bonus:** Can you interpret the weights in *func_model.get_weights()*?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:27:41.373047Z",
     "start_time": "2019-08-08T10:27:40.970363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 1)            6           input_28[0][0]                   \n",
      "                                                                 input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2)            0           dense_40[0][0]                   \n",
      "                                                                 dense_40[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 4)            12          concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1)            5           dense_41[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# This returns a tensor\n",
    "s1_size = S1.shape[1]\n",
    "s2_size = S2.shape[1]\n",
    "inputs1 = Input(shape=(s1_size,))\n",
    "inputs2 = Input(shape=(s2_size,))\n",
    "\n",
    "\n",
    "shared_dense = Dense(1, activation='sigmoid')\n",
    "x1 = shared_dense(inputs1) \n",
    "x2 = shared_dense(inputs2)\n",
    "merged = keras.layers.concatenate([x1, x2], axis = -1)\n",
    "\n",
    "dense1 = Dense(4, activation='sigmoid')(merged)\n",
    "predictions = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "func_model = Model(inputs=[inputs1, inputs2], outputs = predictions) \n",
    "func_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:28:26.572293Z",
     "start_time": "2019-08-08T10:27:44.754162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.7212 - acc: 0.4975 - val_loss: 0.7160 - val_acc: 0.4750\n",
      "Epoch 2/60\n",
      "800/800 [==============================] - 0s 582us/step - loss: 0.7004 - acc: 0.4975 - val_loss: 0.7037 - val_acc: 0.4750\n",
      "Epoch 3/60\n",
      "800/800 [==============================] - 1s 795us/step - loss: 0.6930 - acc: 0.4200 - val_loss: 0.6982 - val_acc: 0.2350\n",
      "Epoch 4/60\n",
      "800/800 [==============================] - 0s 542us/step - loss: 0.6901 - acc: 0.2763 - val_loss: 0.6955 - val_acc: 0.2050\n",
      "Epoch 5/60\n",
      "800/800 [==============================] - 0s 541us/step - loss: 0.6886 - acc: 0.3163 - val_loss: 0.6939 - val_acc: 0.4850\n",
      "Epoch 6/60\n",
      "800/800 [==============================] - 0s 553us/step - loss: 0.6880 - acc: 0.5338 - val_loss: 0.6935 - val_acc: 0.4850\n",
      "Epoch 7/60\n",
      "800/800 [==============================] - 1s 683us/step - loss: 0.6872 - acc: 0.6875 - val_loss: 0.6934 - val_acc: 0.4850\n",
      "Epoch 8/60\n",
      "800/800 [==============================] - 0s 613us/step - loss: 0.6867 - acc: 0.4863 - val_loss: 0.6928 - val_acc: 0.4850\n",
      "Epoch 9/60\n",
      "800/800 [==============================] - 1s 639us/step - loss: 0.6857 - acc: 0.5125 - val_loss: 0.6920 - val_acc: 0.4850\n",
      "Epoch 10/60\n",
      "800/800 [==============================] - 1s 792us/step - loss: 0.6848 - acc: 0.5125 - val_loss: 0.6913 - val_acc: 0.4850\n",
      "Epoch 11/60\n",
      "800/800 [==============================] - 1s 891us/step - loss: 0.6837 - acc: 0.5838 - val_loss: 0.6905 - val_acc: 0.7250\n",
      "Epoch 12/60\n",
      "800/800 [==============================] - 1s 813us/step - loss: 0.6824 - acc: 0.5438 - val_loss: 0.6896 - val_acc: 0.7250\n",
      "Epoch 13/60\n",
      "800/800 [==============================] - 1s 818us/step - loss: 0.6810 - acc: 0.6788 - val_loss: 0.6887 - val_acc: 0.4850\n",
      "Epoch 14/60\n",
      "800/800 [==============================] - 1s 783us/step - loss: 0.6793 - acc: 0.6550 - val_loss: 0.6873 - val_acc: 0.4850\n",
      "Epoch 15/60\n",
      "800/800 [==============================] - 1s 817us/step - loss: 0.6773 - acc: 0.5888 - val_loss: 0.6855 - val_acc: 0.7250\n",
      "Epoch 16/60\n",
      "800/800 [==============================] - 1s 891us/step - loss: 0.6750 - acc: 0.7288 - val_loss: 0.6840 - val_acc: 0.4850\n",
      "Epoch 17/60\n",
      "800/800 [==============================] - 1s 730us/step - loss: 0.6726 - acc: 0.5950 - val_loss: 0.6817 - val_acc: 0.4850\n",
      "Epoch 18/60\n",
      "800/800 [==============================] - 1s 702us/step - loss: 0.6695 - acc: 0.5275 - val_loss: 0.6788 - val_acc: 0.4850\n",
      "Epoch 19/60\n",
      "800/800 [==============================] - 1s 959us/step - loss: 0.6660 - acc: 0.6550 - val_loss: 0.6757 - val_acc: 0.7250\n",
      "Epoch 20/60\n",
      "800/800 [==============================] - 1s 914us/step - loss: 0.6621 - acc: 0.5588 - val_loss: 0.6720 - val_acc: 0.7250\n",
      "Epoch 21/60\n",
      "800/800 [==============================] - 0s 598us/step - loss: 0.6577 - acc: 0.7688 - val_loss: 0.6678 - val_acc: 0.7250\n",
      "Epoch 22/60\n",
      "800/800 [==============================] - 1s 693us/step - loss: 0.6526 - acc: 0.7525 - val_loss: 0.6631 - val_acc: 0.7250\n",
      "Epoch 23/60\n",
      "800/800 [==============================] - 1s 675us/step - loss: 0.6470 - acc: 0.6425 - val_loss: 0.6576 - val_acc: 0.7250\n",
      "Epoch 24/60\n",
      "800/800 [==============================] - 1s 632us/step - loss: 0.6410 - acc: 0.7700 - val_loss: 0.6518 - val_acc: 0.7250\n",
      "Epoch 25/60\n",
      "800/800 [==============================] - 1s 795us/step - loss: 0.6343 - acc: 0.7700 - val_loss: 0.6453 - val_acc: 0.7250\n",
      "Epoch 26/60\n",
      "800/800 [==============================] - 1s 719us/step - loss: 0.6269 - acc: 0.7700 - val_loss: 0.6382 - val_acc: 0.7250\n",
      "Epoch 27/60\n",
      "800/800 [==============================] - 1s 781us/step - loss: 0.6187 - acc: 0.7700 - val_loss: 0.6305 - val_acc: 0.7250\n",
      "Epoch 28/60\n",
      "800/800 [==============================] - 1s 678us/step - loss: 0.6104 - acc: 0.7700 - val_loss: 0.6223 - val_acc: 0.7250\n",
      "Epoch 29/60\n",
      "800/800 [==============================] - 1s 764us/step - loss: 0.6011 - acc: 0.7700 - val_loss: 0.6135 - val_acc: 0.7250\n",
      "Epoch 30/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5914 - acc: 0.7700 - val_loss: 0.6038 - val_acc: 0.7250\n",
      "Epoch 31/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5814 - acc: 0.7700 - val_loss: 0.5941 - val_acc: 0.7250\n",
      "Epoch 32/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5707 - acc: 0.7700 - val_loss: 0.5840 - val_acc: 0.7250\n",
      "Epoch 33/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5600 - acc: 0.7700 - val_loss: 0.5735 - val_acc: 0.7250\n",
      "Epoch 34/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5489 - acc: 0.7700 - val_loss: 0.5626 - val_acc: 0.7250\n",
      "Epoch 35/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5375 - acc: 0.7700 - val_loss: 0.5513 - val_acc: 0.7250\n",
      "Epoch 36/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5260 - acc: 0.7700 - val_loss: 0.5403 - val_acc: 0.7250\n",
      "Epoch 37/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5146 - acc: 0.7700 - val_loss: 0.5294 - val_acc: 0.7250\n",
      "Epoch 38/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5031 - acc: 0.7700 - val_loss: 0.5184 - val_acc: 0.7250\n",
      "Epoch 39/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4918 - acc: 0.7700 - val_loss: 0.5072 - val_acc: 0.7250\n",
      "Epoch 40/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4806 - acc: 0.7700 - val_loss: 0.4961 - val_acc: 0.7250\n",
      "Epoch 41/60\n",
      "800/800 [==============================] - 1s 787us/step - loss: 0.4694 - acc: 0.7700 - val_loss: 0.4849 - val_acc: 0.7250\n",
      "Epoch 42/60\n",
      "800/800 [==============================] - 1s 823us/step - loss: 0.4582 - acc: 0.7700 - val_loss: 0.4739 - val_acc: 0.7250\n",
      "Epoch 43/60\n",
      "800/800 [==============================] - 1s 801us/step - loss: 0.4474 - acc: 0.7700 - val_loss: 0.4630 - val_acc: 0.7250\n",
      "Epoch 44/60\n",
      "800/800 [==============================] - 1s 758us/step - loss: 0.4366 - acc: 0.7700 - val_loss: 0.4520 - val_acc: 0.7250\n",
      "Epoch 45/60\n",
      "800/800 [==============================] - 0s 539us/step - loss: 0.4259 - acc: 0.7700 - val_loss: 0.4409 - val_acc: 0.7250\n",
      "Epoch 46/60\n",
      "800/800 [==============================] - 1s 779us/step - loss: 0.4154 - acc: 0.7700 - val_loss: 0.4303 - val_acc: 0.7250\n",
      "Epoch 47/60\n",
      "800/800 [==============================] - 0s 558us/step - loss: 0.4054 - acc: 0.7700 - val_loss: 0.4197 - val_acc: 0.7250\n",
      "Epoch 48/60\n",
      "800/800 [==============================] - 0s 553us/step - loss: 0.3948 - acc: 0.7700 - val_loss: 0.4080 - val_acc: 0.7250\n",
      "Epoch 49/60\n",
      "800/800 [==============================] - 0s 598us/step - loss: 0.3839 - acc: 0.7700 - val_loss: 0.3966 - val_acc: 0.7250\n",
      "Epoch 50/60\n",
      "800/800 [==============================] - 1s 765us/step - loss: 0.3732 - acc: 0.9313 - val_loss: 0.3852 - val_acc: 1.0000\n",
      "Epoch 51/60\n",
      "800/800 [==============================] - 1s 859us/step - loss: 0.3621 - acc: 1.0000 - val_loss: 0.3732 - val_acc: 1.0000\n",
      "Epoch 52/60\n",
      "800/800 [==============================] - 0s 543us/step - loss: 0.3510 - acc: 1.0000 - val_loss: 0.3617 - val_acc: 1.0000\n",
      "Epoch 53/60\n",
      "800/800 [==============================] - 0s 578us/step - loss: 0.3401 - acc: 1.0000 - val_loss: 0.3497 - val_acc: 1.0000\n",
      "Epoch 54/60\n",
      "800/800 [==============================] - 1s 780us/step - loss: 0.3290 - acc: 1.0000 - val_loss: 0.3376 - val_acc: 1.0000\n",
      "Epoch 55/60\n",
      "800/800 [==============================] - 1s 794us/step - loss: 0.3179 - acc: 1.0000 - val_loss: 0.3257 - val_acc: 1.0000\n",
      "Epoch 56/60\n",
      "800/800 [==============================] - 1s 668us/step - loss: 0.3069 - acc: 1.0000 - val_loss: 0.3138 - val_acc: 1.0000\n",
      "Epoch 57/60\n",
      "800/800 [==============================] - 0s 605us/step - loss: 0.2958 - acc: 1.0000 - val_loss: 0.3020 - val_acc: 1.0000\n",
      "Epoch 58/60\n",
      "800/800 [==============================] - 0s 616us/step - loss: 0.2851 - acc: 1.0000 - val_loss: 0.2908 - val_acc: 1.0000\n",
      "Epoch 59/60\n",
      "800/800 [==============================] - 1s 735us/step - loss: 0.2744 - acc: 1.0000 - val_loss: 0.2794 - val_acc: 1.0000\n",
      "Epoch 60/60\n",
      "800/800 [==============================] - 0s 614us/step - loss: 0.2638 - acc: 1.0000 - val_loss: 0.2685 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb35a02c88>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.fit([S1, S2], labels, epochs = 60, batch_size=5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:16:40.201445Z",
     "start_time": "2019-08-08T10:16:40.136324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.09172858],\n",
       "        [-0.7042335 ],\n",
       "        [-0.7649352 ],\n",
       "        [-0.13719936],\n",
       "        [-0.5824953 ]], dtype=float32),\n",
       " array([0.0379861], dtype=float32),\n",
       " array([[-4.749326  , -4.9802036 , -2.562598  ,  0.51760924],\n",
       "        [-4.9069147 ,  2.6551414 , -2.383913  , -2.4291945 ]],\n",
       "       dtype=float32),\n",
       " array([ 1.0781835 , -1.2654732 , -0.5169826 ,  0.03580838], dtype=float32),\n",
       " array([[ 3.6189485],\n",
       "        [-2.6134408],\n",
       "        [ 1.2085513],\n",
       "        [-1.3698591]], dtype=float32),\n",
       " array([0.28909597], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:20:21.485302Z",
     "start_time": "2019-08-08T10:20:21.476660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 5), (None, 5)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:20:23.045760Z",
     "start_time": "2019-08-08T10:20:23.040754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:20:35.710074Z",
     "start_time": "2019-08-08T10:20:35.685519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:20:42.261071Z",
     "start_time": "2019-08-08T10:20:42.253231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T10:20:46.420335Z",
     "start_time": "2019-08-08T10:20:46.411458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy reaches 1.000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NMT Exercise 1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
