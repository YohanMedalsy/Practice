{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:45:58.299805Z",
     "start_time": "2019-08-04T18:45:39.746125Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3:\n",
    "\n",
    "A credit card company is ramping up their Data Science Department and just hired you. They have just integrated their data on credit card usage and personal information (like education and location). Further, since they have a personal loans department, they also know, for the people that took a loan, their annual income, credit score, and whether they own a home.\n",
    "\n",
    "They have 5.2 million clients, but only 100k of them* have taken a loan. Below is the data for each of the 100k, along with their income.\n",
    "\n",
    "Your goal is to create a model that predicts a person's annual income given all the other features.\n",
    "\n",
    "* for simplicity, assume that those 100k properly represent the 5.2M and don't have any sampling biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:45:59.359102Z",
     "start_time": "2019-08-04T18:45:58.313162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_degrees</th>\n",
       "      <th>has_technical_degree</th>\n",
       "      <th>max_spend_in_a_month</th>\n",
       "      <th>num_purchases_last_3_months</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>owns_home</th>\n",
       "      <th>lived_in_NYC</th>\n",
       "      <th>lived_in_SF</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4178.724200</td>\n",
       "      <td>456</td>\n",
       "      <td>714.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>88.448668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3501.739244</td>\n",
       "      <td>86</td>\n",
       "      <td>669.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39.494271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3298.700962</td>\n",
       "      <td>39</td>\n",
       "      <td>680.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>84.836224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3052.162814</td>\n",
       "      <td>31</td>\n",
       "      <td>697.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>132.722244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2601.803821</td>\n",
       "      <td>141</td>\n",
       "      <td>702.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>77.237528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_degrees  has_technical_degree  max_spend_in_a_month  \\\n",
       "0                1.0                 False           4178.724200   \n",
       "1                0.0                 False           3501.739244   \n",
       "2                1.0                 False           3298.700962   \n",
       "3                0.0                 False           3052.162814   \n",
       "4                1.0                  True           2601.803821   \n",
       "\n",
       "   num_purchases_last_3_months  credit_score  owns_home  lived_in_NYC  \\\n",
       "0                          456         714.0      False         False   \n",
       "1                           86         669.0       True         False   \n",
       "2                           39         680.0       True         False   \n",
       "3                           31         697.0       True         False   \n",
       "4                          141         702.0      False         False   \n",
       "\n",
       "   lived_in_SF      income  \n",
       "0        False   88.448668  \n",
       "1        False   39.494271  \n",
       "2        False   84.836224  \n",
       "3         True  132.722244  \n",
       "4         True   77.237528  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_matrix = pd.read_csv('income_matrix_ex3.csv', compression='gzip')\n",
    "income_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:45:59.411619Z",
     "start_time": "2019-08-04T18:45:59.370428Z"
    }
   },
   "outputs": [],
   "source": [
    "income_matrix[\"lived_in_SF\"] = np.where(income_matrix[\"lived_in_SF\"], 1, 0)\n",
    "income_matrix[\"lived_in_NYC\"] = np.where(income_matrix[\"lived_in_NYC\"], 1, 0)\n",
    "income_matrix[\"owns_home\"] = np.where(income_matrix[\"owns_home\"], 1, 0)\n",
    "income_matrix[\"has_technical_degree\"] = np.where(income_matrix[\"has_technical_degree\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:45:59.519180Z",
     "start_time": "2019-08-04T18:45:59.421244Z"
    }
   },
   "outputs": [],
   "source": [
    "y = income_matrix[\"income\"]\n",
    "X = income_matrix.drop([\"income\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A1\n",
    "\n",
    "Train a model with 20% on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:08.393871Z",
     "start_time": "2019-08-04T18:45:59.531871Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:10.203482Z",
     "start_time": "2019-08-04T18:46:08.401661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yohan/Desktop/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/Yohan/Desktop/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/Yohan/Desktop/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/Yohan/Desktop/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm_features = ['number_of_degrees', 'max_spend_in_a_month', 'credit_score']\n",
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "mm_scaler.fit(X_train[norm_features])\n",
    "X_train[norm_features] = mm_scaler.transform(X_train[norm_features])\n",
    "X_test[norm_features] = mm_scaler.transform(X_test[norm_features ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:11.585345Z",
     "start_time": "2019-08-04T18:46:10.212027Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3A2\n",
    "\n",
    "How would you describe the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:11.644537Z",
     "start_time": "2019-08-04T18:46:11.600396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22006966581774134"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:11.728379Z",
     "start_time": "2019-08-04T18:46:11.660498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22008399444758053"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "y_pred = reg.predict(X_test)\n",
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use the explained variance (adjusted R score) over the R score because it adjusts the score for the number of features used (this can lead to overfitting) whereas the r score does not make this adjustment. The R score would simply increase by default the more features we add, which is not what we want. However in our case we can see that they are very similar, which is an indication of less overfitting. Furthermore, as can be seen above, there is only a 22.6% accuracy for the model. This means that the model is not a very good predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B\n",
    "\n",
    "Your company has just struck a partnership with Tesla! Part of this deal means that you now have to identify the top earners in your database (to send them ads). For each person that buys a car through your ad, your company will get 0.85% of the value of the purchase.\n",
    "\n",
    "The CMO has taught you that it is well-known that one's income (in particular making over 165k) is all that matters when it comes to the likelihood of buying a Tesla, and he has decided to allocate budget to advertise to 260k people. Now 0.85% of a Tesla is a lot, so you better pick the right people! Describe how your model will do in picking the right 260k people. Please write down a sentence or two explaining why you picked that metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suddenly becomes a classification problem where the top x% by salary are 1 and the others 0. To pick the right 260k people I will find the proportion 260k people is out of 5.2 million and then knowing this I will take the top x% by true salary and classify them as 1 and the rest as 0. Then using the predicted incomes I will do the same. I would be optimizing the precision with this approach because 0.85% of a Tesla is a lot which means that the cost of a false positive is very high. Therefore, the precision is a good metric because it minimizes the false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:11.775113Z",
     "start_time": "2019-08-04T18:46:11.743611Z"
    }
   },
   "outputs": [],
   "source": [
    "p_ads = 260000/5200000\n",
    "\n",
    "ad_qty = int(y_test.shape[0]*p_ads)\n",
    "ad_cutoff = np.partition(y_test, -ad_qty)[-ad_qty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:11.810127Z",
     "start_time": "2019-08-04T18:46:11.783298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_ad = np.where(y_test>=ad_cutoff, 1, 0)\n",
    "y_test_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:11.841706Z",
     "start_time": "2019-08-04T18:46:11.821626Z"
    }
   },
   "outputs": [],
   "source": [
    "ad_qty = int(y_pred.shape[0]*p_ads)\n",
    "ad_cutoff = np.partition(y_pred, -ad_qty)[-ad_qty]\n",
    "y_pred_ad = np.where(y_pred>=ad_cutoff, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:11.931604Z",
     "start_time": "2019-08-04T18:46:11.850658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6247368421052631 of all the ads will be properly targeted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "ad_precision = precision_score(y_test_ad, y_pred_ad, average='macro') \n",
    "print(\"{} of all the ads will be properly targeted\".format(ad_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3C\n",
    "\n",
    "The Tesla campaign has gone so fantastically well that your CEO has decided to do something good for the community. Yay! She has created a pro bono partnership with the local hospitals to help low income residents understand their options for treatment. You will help them identify all residents that you think earn less than the median annual income (which are the ones eligible for benefits).\n",
    "\n",
    "How does your model do against that goal? Please write down a sentence or two explaining why you picked that metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:48:29.140634Z",
     "start_time": "2019-08-04T18:48:29.104823Z"
    }
   },
   "outputs": [],
   "source": [
    "median_income = y_train.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:51:15.055093Z",
     "start_time": "2019-08-04T18:51:14.970308Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_ben = np.where(y_test<median_income, 1, 0)\n",
    "y_pred_ben = np.where(y_pred<median_income, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:51:53.760849Z",
     "start_time": "2019-08-04T18:51:53.729259Z"
    }
   },
   "source": [
    "Here I would use an F1 score because I think that both the false positive and false negatives have high costs. The false positives are bad for the company because they are handing out benefits to people that have a higher than median salary, so the money would be wasted on people that do not need the free money. On the other hand false negatives are families that need the benefits but do not receive them which is also very bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:58:56.826316Z",
     "start_time": "2019-08-04T18:58:56.780972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.6746347823443146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "my_f1_score = f1_score(y_test_ben, y_pred_ben, average='macro')  \n",
    "print(\"F1 score: {}\".format(my_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D\n",
    "\n",
    "Your company is doing so well that almost everyone in the US has a credit card with you! Continuing with the pro bono work, a few small cities (of around 200-400 people each) have decided that they want to start collecting city taxes, and your company has offered to help them estimate how much taxes they could raise.\n",
    "\n",
    "All these cities will charge about 2.5% city-tax, and your goal is to estimate as precisely as possible how much tax revenue will be brought. How do you expect your model to do against that goal?  Please write down a sentence or two explaining why you picked that metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T18:46:12.087138Z",
     "start_time": "2019-08-04T18:46:12.020724Z"
    }
   },
   "source": [
    "Here is all about mazimizing the accuracy of the model and in our case to avoid overfitting, we would need to maximize the r score adjusted. I do not expect my model to do very well against this goal because it has a very low r score adjusted of 22% for predicting income. I cannot isolate how it would do for small cities as I do not have the appropriate features for this. Using the general model's results is enough eitherway because it represents all american populations reasonably well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
