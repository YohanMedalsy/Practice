{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, collections, itertools\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from inspect import signature\n",
    "\n",
    "def udf(f):\n",
    "    returnType = T._type_mappings[signature(f).return_annotation]()\n",
    "    return F.UserDefinedFunction(f, returnType)\n",
    "\n",
    "local_dir = \"file:///{d}/\".format(d=os.getcwd())\n",
    "\n",
    "if 'sc' not in globals():\n",
    "    conf = SparkConf().setAppName('appName').setMaster('local')\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easier (in this pyspark version) to first load the data as an RDD, and then modify it into a dataFrame. During this process we also remove the header using a combination of _zipWithIndex()_ and _filter()_ (taken from [here][1]). By looking at the file we see the \"schema\", which is used by the second _map()_.\n",
    "\n",
    "[1]: http://stackoverflow.com/a/31798247/3121900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+-----+\n",
      "|  a|  b|  c|  d|  e|  f|  g|digit|\n",
      "+---+---+---+---+---+---+---+-----+\n",
      "|  0|  1|  1|  0|  0|  1|  1| four|\n",
      "|  0|  0|  1|  1|  0|  1|  1| five|\n",
      "|  1|  1|  1|  0|  1|  1|  1|eight|\n",
      "|  1|  1|  1|  1|  0|  1|  1| nine|\n",
      "|  1|  1|  0|  1|  1|  1|  1|eight|\n",
      "+---+---+---+---+---+---+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "digits = spark.read.csv(\"digits.csv\", \n",
    "                        header=True, inferSchema=True)\n",
    "digits.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data (for ML API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained earlier, _pyspark.ml_ models expect the features to be assembled together as a single **vector**. For that we have to use the _VectorAssembler_ **transformer** and create a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+-----+--------------------+\n",
      "|  a|  b|  c|  d|  e|  f|  g|digit|            features|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+\n",
      "|  0|  1|  1|  0|  0|  1|  1| four|[0.0,1.0,1.0,0.0,...|\n",
      "|  0|  0|  1|  1|  0|  1|  1| five|[0.0,0.0,1.0,1.0,...|\n",
      "|  1|  1|  1|  0|  1|  1|  1|eight|[1.0,1.0,1.0,0.0,...|\n",
      "|  1|  1|  1|  1|  0|  1|  1| nine|[1.0,1.0,1.0,1.0,...|\n",
      "|  1|  1|  0|  1|  1|  1|  1|eight|[1.0,1.0,0.0,1.0,...|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler(inputCols=list('abcdefg'),\n",
    "                     outputCol='features')\n",
    "digits = va.transform(digits)\n",
    "digits.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained earlier, _pyspark.ml_ models cannot deal with non-numeric datatypes, therefore we have to encode such data as numbers. To that end we use the _StringIndexer_ **estimator** and **transformer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+\n",
      "|  a|  b|  c|  d|  e|  f|  g|digit|            features|digit (indexed)|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+\n",
      "|  0|  1|  1|  0|  0|  1|  1| four|[0.0,1.0,1.0,0.0,...|            8.0|\n",
      "|  0|  0|  1|  1|  0|  1|  1| five|[0.0,0.0,1.0,1.0,...|            4.0|\n",
      "|  1|  1|  1|  0|  1|  1|  1|eight|[1.0,1.0,1.0,0.0,...|            1.0|\n",
      "|  1|  1|  1|  1|  0|  1|  1| nine|[1.0,1.0,1.0,1.0,...|            3.0|\n",
      "|  1|  1|  0|  1|  1|  1|  1|eight|[1.0,1.0,0.0,1.0,...|            1.0|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "si = StringIndexer(inputCol='digit',\n",
    "                   outputCol='digit (indexed)')\n",
    "digits = si.fit(digits).transform(digits)\n",
    "digits.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on in the process we would probably apply the classification model which will inevitably produce the encoded (indexed) labels, so a natural question is how to interpret these numbers. Luckilly, like any other estimator, after fitting the data, the _StringIndexerModel_ holds some metadata of the model itself. This information is part of the data, and can be accessed by the following syntax (adopted from [this Stack Overflow answer][1]).\n",
    "\n",
    "[1]: http://stackoverflow.com/a/33903867/3121900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zero', 'eight', 'seven', 'nine', 'five', 'six', 'three', 'one', 'four', 'two']\n"
     ]
    }
   ],
   "source": [
    "labels = digits.schema.fields[-1].metadata['ml_attr']['vals']\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in a more readable fashion..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'zero'), (1, 'eight'), (2, 'seven'), (3, 'nine'), (4, 'five'), (5, 'six'), (6, 'three'), (7, 'one'), (8, 'four'), (9, 'two')]\n"
     ]
    }
   ],
   "source": [
    "print (list(enumerate(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more exciting, we will be able to use the _IndexToString_ method to \"return the wheel\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = digits.randomSplit([0.7, 0.3],\n",
    "                                 seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we instantiate the [_DecisionTreeClassifier_][1] **estimator**.\n",
    "\n",
    "[1]: http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier \"DecisionTreeClassifier API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.classification.DecisionTreeClassifier'>\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol='features',\n",
    "                            labelCol='digit (indexed)',\n",
    "                            maxDepth=5)\n",
    "print (type(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fit the estimator to get the **model**, which is a **transformer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.classification.DecisionTreeClassificationModel'>\n"
     ]
    }
   ],
   "source": [
    "dt_model = dt.fit(train)\n",
    "print (type(dt_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_spark.ml_ does not support visualizations at the moment, but we do have a textual representation of the tree by calling the _toDebugString_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_ed195110a153) of depth 5 with 21 nodes\n",
      "  If (feature 6 <= 0.5)\n",
      "   If (feature 3 <= 0.5)\n",
      "    If (feature 0 <= 0.5)\n",
      "     Predict: 7.0\n",
      "    Else (feature 0 > 0.5)\n",
      "     Predict: 2.0\n",
      "   Else (feature 3 > 0.5)\n",
      "    Predict: 0.0\n",
      "  Else (feature 6 > 0.5)\n",
      "   If (feature 1 <= 0.5)\n",
      "    If (feature 4 <= 0.5)\n",
      "     Predict: 4.0\n",
      "    Else (feature 4 > 0.5)\n",
      "     Predict: 5.0\n",
      "   Else (feature 1 > 0.5)\n",
      "    If (feature 4 <= 0.5)\n",
      "     If (feature 0 <= 0.5)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print (dt_model.toDebugString[:500])  # partial printout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the features importances using the attribute [featureImportances][1], which returns a vector.\n",
    "\n",
    "[1]: http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassificationModel.featureImportances \"featureImportances API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x115956410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = dt_model.featureImportances\n",
    "zip('abcdefg', importances.toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the model to predict the digit of the data used to train the model. We get three columns:\n",
    "\n",
    "* _rawPrediction_ - counts of the predictions assigned to this specific set of features\n",
    "* _probability_ - normalized rawPrediction, reflecting the probabilities of the predictions.\n",
    "* _prediction_ - the actual label corresponding to the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|  a|  b|  c|  d|  e|  f|  g|digit|            features|digit (indexed)|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|  0|  1|  0|  1|  1|  0|  1|  two|[0.0,1.0,0.0,1.0,...|            9.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       9.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = dt_model.transform(train)\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 14.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0])),\n",
       " Row(rawPrediction=DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 1.0, 0.0]))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('rawPrediction').take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [MulticlassClassificationEvaluator][1] object to evaluat the model. This is a new type of object called **evaluator**.\n",
    "\n",
    "[1]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.evaluation.MulticlassClassificationEvaluator'>\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                              labelCol=\"digit (indexed)\",\n",
    "                                              metricName=\"accuracy\")\n",
    "print (type(evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9456521739130435\n"
     ]
    }
   ],
   "source": [
    "print (evaluator.evaluate(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note about MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said before, the _pyspark.ml_ is constantly growing, but still it lacks many features that have already been developed and implemented in [_pyspark.mllib_][1]. One of these functionalities is the confusion matrix, and to illustrate teh differences we will now use the [_MulticlassMetrics_][2] method from the _pyspark.mllib.evaluation_ module.\n",
    "\n",
    "[1]: http://spark.apache.org/docs/2.0.2/api/python/pyspark.mllib.html \"pyspark.mllib API\"\n",
    "[2]: http://spark.apache.org/docs/2.0.2/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.MulticlassMetrics \"MulticlassMetrics API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by noting that the _pyspark.mllib_ module utilizes **RDDs**, which are available thorugh the _rdd_ attribute of the _DataFrame_ class. From the documentation of the _MulticlassMetrics()_ method we learn that it requires an RDD containing only the predictions and the labels, so we select the relevant columns of the DataFrame using the method [_select()_][1] and create the proper RDD.\n",
    "\n",
    "[1]: http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.select \"DataFrame.select() API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=9.0, digit (indexed)=9.0),\n",
       " Row(prediction=7.0, digit (indexed)=7.0),\n",
       " Row(prediction=7.0, digit (indexed)=7.0),\n",
       " Row(prediction=7.0, digit (indexed)=7.0),\n",
       " Row(prediction=7.0, digit (indexed)=7.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionAndLabels = train\\\n",
    "    .select(['prediction', 'digit (indexed)'])\\\n",
    "    .rdd\n",
    "predictionAndLabels.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.evaluation.MulticlassMetrics'>\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print (type(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[21.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "             [ 0., 23.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "             [ 0.,  0., 20.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
      "             [ 0.,  1.,  0., 19.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  0., 21.,  1.,  0.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  1., 12.,  0.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  1.,  0.,  0., 12.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 20.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., 12.,  1.],\n",
      "             [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0., 14.]])\n"
     ]
    }
   ],
   "source": [
    "print (metrics.confusionMatrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** As part of the unified API pyspark is trying to expose, there is a class called [_Param_][1], which is utilized by all the models in _pyspark.ml_. In this session, however, we will use the parameters in their simplest form - key-word arguments of the estimator.\n",
    "\n",
    "[1]: http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#module-pyspark.ml.param \"pyspark.ml.param API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each **estimator** contains some documentation about its parameters, available by the methods _explainParam()_ and _explainParams()_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval. (default: False)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkC\n"
     ]
    }
   ],
   "source": [
    "print (dt.explainParams()[:564])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5, current: 5)\n"
     ]
    }
   ],
   "source": [
    "print (dt.explainParam('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we instantiated the estimator we used the default values, but of course we can tweek the model by changing its parameters. The method [_setParams()_][1], which is available for all _pyspark.ml_ estimators, allows to easily modify the model parameters. We note that it is possible and advisable to use the [\\*\\*kwargs notation][2] when calling this method.\n",
    "\n",
    "[1]: http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier.setParams \"setParams() API\"\n",
    "[2]: http://book.pythontips.com/en/latest/args_and_kwargs.html \"kwargs explanation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier_ed195110a153"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'maxDepth':10}\n",
    "dt.setParams(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the parameters were indeed changed by looking at the explanation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5, current: 10)\n"
     ]
    }
   ],
   "source": [
    "print (dt.explainParam('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the steps of the process described earlier. We note that it is necessary to overwrite _train_ and _test_, otherwise we will get an error in the fit step, because a column with the name _prediction_ alredy exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = digits.randomSplit([0.7, 0.3], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|  a|  b|  c|  d|  e|  f|  g|digit|            features|digit (indexed)|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|  0|  1|  0|  1|  1|  0|  1|  two|[0.0,1.0,0.0,1.0,...|            9.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       9.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = dt.fit(train).transform(train)\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9456521739130435\n"
     ]
    }
   ],
   "source": [
    "print (evaluator.evaluate(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the model to the test data and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|  a|  b|  c|  d|  e|  f|  g|digit|            features|digit (indexed)|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "|  0|  0|  1|  1|  0|  1|  1| five|[0.0,0.0,1.0,1.0,...|            4.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|  0|  1|  0|  0|  0|  0|  0|  one|       (7,[1],[1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "|  0|  1|  0|  0|  0|  1|  1| four|(7,[1,5,6],[1.0,1...|            8.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       8.0|\n",
      "|  0|  1|  1|  0|  0|  0|  0|  one| (7,[1,2],[1.0,1.0])|            7.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       7.0|\n",
      "|  0|  1|  1|  0|  0|  1|  1| four|[0.0,1.0,1.0,0.0,...|            8.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       8.0|\n",
      "+---+---+---+---+---+---+---+-----+--------------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = dt_model.transform(test)\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "print (evaluator.evaluate(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "             [ 1.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  6.,  1.,  0.,  0.,  0.,  1.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  0., 11.,  0.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  1.,  0.,  9.,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.],\n",
      "             [ 0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels = test\\\n",
    "    .select(['prediction', 'digit (indexed)'])\\\n",
    "    .rdd\n",
    "print (MulticlassMetrics(predictionAndLabels).confusionMatrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "\n",
    "* Part I - Create a classification model for predicting the sex of the guys listed in the weight.txt file based on their heights and weights.\n",
    "* Part II - Repeat the previous task, but now use also the age as a feature. Did it improve the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    " The file dessert.csv contains some information about groups who arrived at a restaurant, and the field “dessert” states whether they purchased a dessert or not. Use the file to develop a classification model for predicting which groups will order a dessert. Do not forget to split your data and validate your models.\n",
    "\n",
    "* Part I - Develop the classification model, where “num.of.guests” is an integer.\n",
    "* Part II - Improve your model by considering “num.of.guests” as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "Decision trees with PySpark",
  "notebookId": 3948141445357954
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
