{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, collections, itertools\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from inspect import signature\n",
    "\n",
    "def udf(f):\n",
    "    returnType = T._type_mappings[signature(f).return_annotation]()\n",
    "    return F.UserDefinedFunction(f, returnType)\n",
    "\n",
    "local_dir = \"file:///{d}/\".format(d=os.getcwd())\n",
    "\n",
    "if 'sc' not in globals():\n",
    "    conf = SparkConf().setAppName('appName').setMaster('local')\n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easier (in this pyspark version) to first load the data as an RDD, and then modify it into a dataFrame. During this process we also remove the header using a combination of _zipWithIndex()_ and _filter()_ (taken from [here][1]). By looking at the file we see the \"schema\", which is used by the second _map()_.\n",
    "\n",
    "[1]: http://stackoverflow.com/a/31798247/3121900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+------+\n",
      "|Sex|Age|Height|Weight|\n",
      "+---+---+------+------+\n",
      "|  f| 26| 171.1|  57.0|\n",
      "|  m| 44| 180.1|  84.7|\n",
      "|  m| 32| 161.9|  73.6|\n",
      "|  m| 27| 176.5|  81.0|\n",
      "|  f| 26| 167.3|  57.4|\n",
      "+---+---+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = spark.read.csv(\"weight.txt\", \n",
    "                         header=True, inferSchema=True)\n",
    "weights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know that the age has no part in the model, so we drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "|Sex|Height|Weight|\n",
      "+---+------+------+\n",
      "|  f| 171.1|  57.0|\n",
      "|  m| 180.1|  84.7|\n",
      "|  m| 161.9|  73.6|\n",
      "|  m| 176.5|  81.0|\n",
      "|  f| 167.3|  57.4|\n",
      "+---+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = weights.drop('Age')\n",
    "weights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will illustrate the basics with the boys data and then repeat the process for the girls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "|Sex|Height|Weight|\n",
      "+---+------+------+\n",
      "|  m| 180.1|  84.7|\n",
      "|  m| 161.9|  73.6|\n",
      "|  m| 176.5|  81.0|\n",
      "|  m| 165.9|  72.1|\n",
      "|  m| 168.6|  77.7|\n",
      "+---+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boys = weights.where(weights.Sex == 'm')\n",
    "boys.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Spark DataFrames were designed to facilitate table-oriented tasks, they are not optimized for the mathematical manipulations required for applying the machine learnign algorithms. To overcome this problem, Spark offers another data structure called **Vector**, which is a list-like data structure.\n",
    "\n",
    "Its role will be more clear later, but for now we can think of it as a special column, collecting together several not-necessarily-the-same-type columns. Vectors can be created by constructors from the _pyspark.ml.linalg_ module, but they can also be created by assembling existing columns with the [_VectorAssembler_][va] transformer.\n",
    "\n",
    "[va]: http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler \"VectorAssembler() API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.feature.VectorAssembler'>\n"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler(inputCols=['Height'], outputCol='features')\n",
    "print (type(va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+\n",
      "|Sex|Height|Weight|features|\n",
      "+---+------+------+--------+\n",
      "|  m| 180.1|  84.7| [180.1]|\n",
      "|  m| 161.9|  73.6| [161.9]|\n",
      "|  m| 176.5|  81.0| [176.5]|\n",
      "|  m| 165.9|  72.1| [165.9]|\n",
      "|  m| 168.6|  77.7| [168.6]|\n",
      "+---+------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boys = va.transform(boys)\n",
    "boys.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boys, test_boys = boys.randomSplit([0.7, 0.3], seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model itself is embodied by the [LinearRegression][1] **estimator** class. The initialization of the estimator requires the declaration of the features by the argument _featuresCol_, the target by the argument _labelCol_ and the future prediction column by the argument _predictionCol_. It does **NOT** require the data itself...\n",
    "\n",
    "[1]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegression \"LinearRegression API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.regression.LinearRegression'>\n"
     ]
    }
   ],
   "source": [
    "boys_lr = LinearRegression(featuresCol='features', \n",
    "                           labelCol='Weight', \n",
    "                           predictionCol='predicted weight')\n",
    "print (type(boys_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being an **estimator**, a _LinearRegression_ object has a **_fit()_** method. This method applies the linear regression algorithm to fit the data in _featureCol_ to the labels in _labelCol_ to create a **model**, which is a type of **transformer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.regression.LinearRegressionModel'>\n"
     ]
    }
   ],
   "source": [
    "boys_lm = boys_lr.fit(train_boys)\n",
    "print (type(boys_lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8359550207720998]\n",
      "-65.4164719973857\n"
     ]
    }
   ],
   "source": [
    "print (boys_lm.coefficients)\n",
    "print (boys_lm.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a **transformer**, a _LinearRegressionModel_ object has a **_transform()_** method. This is the equivalent of the _predict()_ method from scikit-learn, and it applies the applies the model to the data and creates a new column with the name _predictionCol_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+--------+-----------------+\n",
      "|Sex|Height|Weight|features| predicted weight|\n",
      "+---+------+------+--------+-----------------+\n",
      "|  m| 155.7|  64.5| [155.7]|64.74172473683022|\n",
      "|  m| 156.3|  62.4| [156.3]|65.24329774929352|\n",
      "|  m| 157.5|  69.1| [157.5]|66.24644377422003|\n",
      "|  m| 157.8|  68.4| [157.8]|66.49723028045166|\n",
      "|  m| 158.5|  65.2| [158.5]|67.08239879499213|\n",
      "+---+------+------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_boys = boys_lm.transform(train_boys)\n",
    "train_boys.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE (and other measures) are available in the _pyspark.ml.evaluation_ module. As usual, we instantiate an evaluator object with the proper arguments, and then apply it to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.061750977117286\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol=\"predicted weight\", \n",
    "                                labelCol=\"Weight\", \n",
    "                                metricName=\"rmse\")\n",
    "print (evaluator.evaluate(train_boys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the same steps to the test data ([pipeline][1], anyone?) and hope the results will be similar, otherwise we apparently have an overfitting problem.\n",
    "\n",
    "[1]: https://spark.apache.org/docs/2.0.2/ml-pipeline.html \"pipeline documentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0484188962626835\n"
     ]
    }
   ],
   "source": [
    "test_boys = boys_lm.transform(test_boys)\n",
    "print (evaluator.evaluate(test_boys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is exactly the same, so we will show the entire code without verbal explanations and review it to note the minor differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+---------------+---------+\n",
      "|jogging_km|spinning_hr|hamburgers|ice_cream_balls|change_kg|\n",
      "+----------+-----------+----------+---------------+---------+\n",
      "|       269|         29|         6|             35|     -7.5|\n",
      "|        79|         10|        13|             23|     -0.9|\n",
      "|       112|         46|         4|             22|     -6.1|\n",
      "|       172|         27|        14|             28|     -4.7|\n",
      "|       273|         31|        29|             47|     -7.0|\n",
      "+----------+-----------+----------+---------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diet = spark.read.csv(\"diet.txt\", \n",
    "                      sep=';', header=True, inferSchema=True).drop('id')\n",
    "\n",
    "for col_name in diet.columns:\n",
    "  diet = diet.withColumnRenamed(col_name, col_name.replace('.', '_'))\n",
    "  \n",
    "diet.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** Spark does not allow features to have a dot (.) in their name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+---------------+---------+--------------------+\n",
      "|jogging_km|spinning_hr|hamburgers|ice_cream_balls|change_kg|            features|\n",
      "+----------+-----------+----------+---------------+---------+--------------------+\n",
      "|       269|         29|         6|             35|     -7.5|[269.0,29.0,6.0,3...|\n",
      "|        79|         10|        13|             23|     -0.9|[79.0,10.0,13.0,2...|\n",
      "|       112|         46|         4|             22|     -6.1|[112.0,46.0,4.0,2...|\n",
      "|       172|         27|        14|             28|     -4.7|[172.0,27.0,14.0,...|\n",
      "|       273|         31|        29|             47|     -7.0|[273.0,31.0,29.0,...|\n",
      "+----------+-----------+----------+---------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler(inputCols=diet.columns[:-1], outputCol='features')\n",
    "diet = va.transform(diet)\n",
    "diet.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diet, test_diet = diet.randomSplit([0.7, 0.3], seed=1729)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_lr = LinearRegression(featuresCol='features', \n",
    "                           labelCol='change_kg', \n",
    "                           predictionCol='predicted change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_lm = diet_lr.fit(train_diet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04011369017559605,-0.09906748087233982,0.11823546860099315,0.10502143858543478]\n",
      "0.37139828664060204\n"
     ]
    }
   ],
   "source": [
    "print (diet_lm.coefficients)\n",
    "print (diet_lm.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+---------------+---------+--------------------+-------------------+\n",
      "|jogging_km|spinning_hr|hamburgers|ice_cream_balls|change_kg|            features|   predicted change|\n",
      "+----------+-----------+----------+---------------+---------+--------------------+-------------------+\n",
      "|         3|         26|        10|             30|      2.4|[3.0,26.0,10.0,30.0]|  2.008300557005953|\n",
      "|         7|         20|        30|             24|      3.9|[7.0,20.0,30.0,24.0]|  4.176831422044862|\n",
      "|        17|         49|         4|              8|     -4.1| [17.0,49.0,4.0,8.0]| -3.851727626001731|\n",
      "|        18|          2|         3|              9|      0.7|  [18.0,2.0,3.0,9.0]| 0.7511162548070859|\n",
      "|        21|         45|        20|              7|     -0.4|[21.0,45.0,20.0,7.0]|-1.8291664041843005|\n",
      "+----------+-----------+----------+---------------+---------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_diet = diet_lm.transform(train_diet)\n",
    "train_diet.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9169297083439855\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol=\"predicted change\", \n",
    "                                labelCol=\"change_kg\", \n",
    "                                metricName=\"rmse\")\n",
    "print (evaluator.evaluate(train_diet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9171880251134429\n"
     ]
    }
   ],
   "source": [
    "test_diet = diet_lm.transform(test_diet)\n",
    "print (evaluator.evaluate(test_diet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1:\n",
    "Read the grades.txt file. For the sake of this exercise you may ignore the splitting step and use the entire data for the regression.\n",
    "\n",
    "* Part I - Fit three single-variable regression models for the SAT grade based on each of the math grade, the english grade and the literature grade, and analyze them. Which of the models is the best?\n",
    "* Part II - Fit a new linear regression model with all three grades as predictors, and analyze the model. Is the new model better than the previous ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of dummy variables is implemented in _pyspark.ml_ by a combination of two optional **estimators and transformers** - [_StringIndexer_][1] and [_OneHotEncoder_][2]. _StringIndexer_ maps a \"categorical\" feature column of type string into arbitrary integers, and _OneHotEncoder_ maps a column of category indices to a column of binary vectors, with at most a single one-value per row that indicates the input category index. It sounds complicated, but it is not...\n",
    "\n",
    "More generally, the module [_features_][3] of _pyspark.ml_ supports a large family of data transformers, which are documented [here][4].\n",
    "\n",
    "[1]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.feature.StringIndexer \"StringIndexer API\"\n",
    "[2]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.feature.OneHotEncoder \"OneHotEncoder API\"\n",
    "[3]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#module-pyspark.ml.feature \"ml.features API\"\n",
    "[4]: https://spark.apache.org/docs/2.0.2/ml-features.html \"ml.features documentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply this concept to the _gender_ feature we roll back to the step before the vectorizing. This time we consider both boys and girls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------------+\n",
      "|Sex|Height|Weight|Sex (indexed)|\n",
      "+---+------+------+-------------+\n",
      "|  f| 171.1|  57.0|          1.0|\n",
      "|  m| 180.1|  84.7|          0.0|\n",
      "|  m| 161.9|  73.6|          0.0|\n",
      "|  m| 176.5|  81.0|          0.0|\n",
      "|  f| 167.3|  57.4|          1.0|\n",
      "+---+------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "si = StringIndexer(inputCol='Sex', outputCol='Sex (indexed)')\n",
    "si_model = si.fit(weights)\n",
    "weights = si_model.transform(weights)\n",
    "weights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------------+-------------+\n",
      "|Sex|Height|Weight|Sex (indexed)|Sex (one hot)|\n",
      "+---+------+------+-------------+-------------+\n",
      "|  f| 171.1|  57.0|          1.0|(2,[1],[1.0])|\n",
      "|  m| 180.1|  84.7|          0.0|(2,[0],[1.0])|\n",
      "|  m| 161.9|  73.6|          0.0|(2,[0],[1.0])|\n",
      "|  m| 176.5|  81.0|          0.0|(2,[0],[1.0])|\n",
      "|  f| 167.3|  57.4|          1.0|(2,[1],[1.0])|\n",
      "+---+------+------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(inputCol='Sex (indexed)', outputCol='Sex (one hot)')\n",
    "ohe.setDropLast(False)\n",
    "weights = ohe.transform(weights)\n",
    "weights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** _OneHotEncoder()_ returns [sparse vectors][1], which is a standard representation of arrays with a lot of zeroes. In this representation, the tuple (_n_, [_locs_], [_vals_]) means there are _n_ elements in the vector, and the value in location _locs[i]_ is _vals[i]_. This makes the illustration not very intuitive, but we will have to deal with that...\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Sparse_array \"Sparse array - Wikipedia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------------+-------------+---------------+\n",
      "|Sex|Height|Weight|Sex (indexed)|Sex (one hot)|       features|\n",
      "+---+------+------+-------------+-------------+---------------+\n",
      "|  f| 171.1|  57.0|          1.0|(2,[1],[1.0])|[171.1,0.0,1.0]|\n",
      "|  m| 180.1|  84.7|          0.0|(2,[0],[1.0])|[180.1,1.0,0.0]|\n",
      "|  m| 161.9|  73.6|          0.0|(2,[0],[1.0])|[161.9,1.0,0.0]|\n",
      "|  m| 176.5|  81.0|          0.0|(2,[0],[1.0])|[176.5,1.0,0.0]|\n",
      "|  f| 167.3|  57.4|          1.0|(2,[1],[1.0])|[167.3,0.0,1.0]|\n",
      "+---+------+------+-------------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va = VectorAssembler(inputCols=['Height', 'Sex (one hot)'], outputCol='features')\n",
    "weights = va.transform(weights)\n",
    "weights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights, test_weights = weights.randomSplit([0.7, 0.3], seed=8128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_lr = LinearRegression(featuresCol='features', \n",
    "                             labelCol='Weight', \n",
    "                             predictionCol='predicted weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_lm = weight_lr.fit(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7398664663003207,7.981299963618155,-7.981299963620369]\n",
      "-57.164935986522075\n"
     ]
    }
   ],
   "source": [
    "print (weight_lm.coefficients)\n",
    "print (weight_lm.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-------------+-------------+---------------+------------------+\n",
      "|Sex|Height|Weight|Sex (indexed)|Sex (one hot)|       features|  predicted weight|\n",
      "+---+------+------+-------------+-------------+---------------+------------------+\n",
      "|  f| 153.0|  52.1|          1.0|(2,[1],[1.0])|[153.0,0.0,1.0]| 48.05333339380662|\n",
      "|  f| 155.9|  52.6|          1.0|(2,[1],[1.0])|[155.9,0.0,1.0]| 50.19894614607755|\n",
      "|  f| 156.1|  53.6|          1.0|(2,[1],[1.0])|[156.1,0.0,1.0]| 50.34691943933762|\n",
      "|  f| 156.3|  48.3|          1.0|(2,[1],[1.0])|[156.3,0.0,1.0]|50.494892732597684|\n",
      "|  f| 156.6|  51.4|          1.0|(2,[1],[1.0])|[156.6,0.0,1.0]| 50.71685267248777|\n",
      "+---+------+------+-------------+-------------+---------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_weights = weight_lm.transform(train_weights)\n",
    "train_weights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.001442785651967\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol=\"predicted weight\", \n",
    "                                labelCol=\"Weight\", \n",
    "                                metricName=\"rmse\")\n",
    "print (evaluator.evaluate(train_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8654785372425797\n"
     ]
    }
   ],
   "source": [
    "test_weights = weight_lm.transform(test_weights)\n",
    "print (evaluator.evaluate(test_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execrise 2:\n",
    "The file prices.csv contains rental details for many apartments in several cities. Read the file, use its data to create two linear models for estimating the price (part I and part II below), and explain which one is better and why.\n",
    "\n",
    "* Part I - The ‘Rooms’ feature is an integer.\n",
    "* Part II - The ‘Rooms’ feature is a dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "Linear regression with PySpark",
  "notebookId": 2317684797154381
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
