#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Tue Apr 16 17:46:46 2019@author: nadavnehmadi"""import numpy as npimport matplotlib.pyplot as pltX = np.array([[0, 0, 1], [0, 1, 1], [1, 0,1], [1, 1, 1]])Y = np.array([[0], [1], [1], [0]])epochs = 10000inputLayerSize = 3hiddenLayerSize = 3outputLayerSize = 1def sigmoid(x):  #YOUR CODE - activation function    return 1/(1 + np.exp(-x))def sigmoid_(x): #YOUR CODE - derivative of sigmoid    return x*(1-x)Wh = np.random.uniform(size=(inputLayerSize, hiddenLayerSize))Wz = np.random.uniform(size=(hiddenLayerSize, outputLayerSize))for i in range(epochs):    L1 = np.dot(X, Wh) #YOUR CODE - first layer    H = sigmoid(L1) #YOUR CODE - hidden layer results    L2 = np.dot(H, Wz) #YOUR CODE - second layer    Z = sigmoid(L2) #YOUR CODE - output layer results    E = Y - Z #YOUR CODE - how much we missed (error)    dZ = E * sigmoid_(Z)    dH = np.dot(dZ, Wz.T) * sigmoid_(H) #YOUR CODE -  # delta H    Wz += np.dot(H.T, dZ) #YOUR CODE - update output layer weights    Wh += np.dot(X.T, dH) #YOUR CODE - update hidden layer weightsprint(Z)  # what have we learn?